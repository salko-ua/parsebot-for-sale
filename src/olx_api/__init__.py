import re
import requests
from aiogram import types
from aiogram.utils.media_group import MediaGroupBuilder
from bs4 import BeautifulSoup
from bs4.element import Tag

class Parser:
    def __init__(self, url):
        self.url = url
        self.response = requests.get(url)
        self.soup = BeautifulSoup(self.response.content, "html.parser")
        self.images = []
        self.amount_of_rooms = ""
        self.floor = ""
        self.area = ""
        self.district = ""
        self.price = ""
        self.header = ""
        self.caption = ""
        self.full_caption = ""

    def update_amount_of_rooms(self, update_to: str) -> None:
        self.amount_of_rooms = update_to
        self.update_full_caption()

    def update_floor(self, update_to: str) -> None:
        self.floor = update_to
        self.update_full_caption()

    def update_area(self, update_to: str) -> None:
        self.area = update_to
        self.update_full_caption()

    def update_district(self, update_to: str) -> None:
        self.district = update_to
        self.update_full_caption()

    def update_price(self, update_to: str) -> None:
        self.price = update_to
        self.update_full_caption()
    
    def update_header(self, update_to: str) -> None:
        self.header = update_to
        self.update_full_caption()

    def update_caption(self, update_to: str) -> None:
        self.caption = update_to
        self.update_full_caption()

    def delete_words(self, text: str, words_to_remove: list) -> str:
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Ä–µ–≥—É–ª—è—Ä–Ω–∏–π –≤–∏—Ä–∞–∑ –¥–ª—è –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Å–ª–æ–≤–∞ –∑ –º–æ–∂–ª–∏–≤–∏–º–∏ –∫—Ä–∞–ø–∫–∞–º–∏
        pattern = re.compile(
            r"\b(?:" + "|".join(map(re.escape, words_to_remove)) + r")\b", re.IGNORECASE
        )

        # –ó–∞–º—ñ–Ω—é—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ —Å–ª–æ–≤–∞ –Ω–∞ –ø–æ—Ä–æ–∂–Ω—ñ —Ä—è–¥–∫–∏
        result = pattern.sub("", text)

        return result

    def reset_header(self) -> None:
        # parsing caption from the page
        header_parent = self.soup.find("div", {"data-testid": "ad_title"})
        if header_parent and isinstance(header_parent, Tag):
            header = header_parent.find(lambda tag: tag.name not in ['style', 'script'])
            header = header.text if header else None
        else:
            header = None

        if not header:
            self.header = "–ó–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –ü–æ–≤—ñ–¥–æ–º—Ç–µ —Ä–æ–∑—Ä–æ–±–Ω–∏–∫–∞ –ø—Ä–æ –ø–æ–º–∏–ª–∫—É."
            return None

        self.header = header
        self.update_full_caption()

    def reset_caption(self) -> None:
        # parsing caption parent
        full_caption = self.soup.find("div", {"data-testid": "ad_description"})
        
        # get caption if he is exist
        if full_caption and isinstance(full_caption, Tag):
            caption = full_caption.find("div")
            caption = caption.text if caption else None
        else:
            caption = None
            
        if caption is None:
            self.caption = "–û–ø–∏—Å –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ."
            return

        if len(caption) > 800:
            self.caption = caption[0:800]
            return

        self.caption = caption
        self.update_full_caption()

    def reset_price(self) -> None:
        # parsing price from the page
          
        price_parent = self.soup.find("div", {"data-testid": "ad-price-container"})
        if price_parent and isinstance(price_parent, Tag):
            price = price_parent.find(lambda tag: tag.name not in ['style', 'script'])
            price = price.text if price else None
        else:
            price = None

        if not price:
            self.price = "–°—É–º—É –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ"
            return

        self.price = price
        self.update_full_caption()

    # Parse main information like (amount of rooms, floor, area, region)
    def reset_main_information(self) -> None:
        # constants to check the list "tags"
        need_words_ukrainian = [
            "–ö—ñ–ª—å–∫—ñ—Å—Ç—å –∫—ñ–º–Ω–∞—Ç:",
            "–ó–∞–≥–∞–ª—å–Ω–∞ –ø–ª–æ—â–∞:",
            "–ü–æ–≤–µ—Ä—Ö:",
            "–ü–æ–≤–µ—Ä—Ö–æ–≤—ñ—Å—Ç—å:",
        ]
        need_words_russian = [
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç:",
            "–û–±—â–∞—è –ø–ª–æ—â–∞–¥—å:",
            "–≠—Ç–∞–∂:",
            "–≠—Ç–∞–∂–Ω–æ—Å—Ç—å:",
        ]

        checklist = []

        # find all span tags in div 
        div_with_tags = self.soup.find("div", class_="css-41yf00")
        if div_with_tags and isinstance(div_with_tags, Tag):
            tags = div_with_tags.find_all("p")
        else:
            tags = []
         
        # check for matches
        for need_word in need_words_russian:
            for tag in tags:
                if need_word in tag.text:
                    checklist.append(tag.text)

        for need_word in need_words_ukrainian:
            for tag in tags:
                if need_word in tag.text:
                    checklist.append(tag.text)
        
        
        # TODO –ø–µ—Ä–µ—Ä–æ–±–∏—Ç–∏ –ø—Ä–∏–Ω—Ü–∏–ø 
        try:
            if len(checklist) != 4:
                rooms = re.search(r"\d+", checklist[0]).group() 
                area = re.search(r"\d+", checklist[1]).group()
                find_everything = re.search(r"\d+", checklist[2])
                floor = f"{find_everything.group()}"
            else:
                rooms = re.search(r"\d+", checklist[0]).group()
                area = re.search(r"\d+", checklist[1]).group()
                find_have = re.search(r"\d+", checklist[2])
                find_everything = re.search(r"\d+", checklist[3])
                floor = f"{find_have.group()} –∑ {find_everything.group()}"
        except:
            rooms, area, floor = "", "", ""

        # -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

        # we are looking for a district and a city, because
        # if there is no district, then the city is a district
        

        # TODO –º–æ–∂–ª–∏–≤–æ –º–æ–∂–Ω–∞ —à—É–∫–∞—Ç–∏ –æ–¥—Ä–∞–∑—É –≤ find? 
        find = self.soup.find_all("script")
        pattern_district = re.compile(r'\\"districtName\\":\\"([^\\"]+)\\"')
        pattern_city = re.compile(r'\\"cityName\\":\\"([^\\"]+)\\"')
        district, city = "", ""

        for one in find:
            district = pattern_district.search(one.text)
            city = pattern_city.search(one.text)
            if district and city:
                break

        if district:
            district = district.group(1)
        elif city:
            district = city.group(1)
        else:
            district = ""

        self.amount_of_rooms = rooms
        self.floor = floor
        self.area = area
        self.district = district
        self.update_full_caption()

    # Parse first 10 photo
    def reset_photo(self) -> None:
        # find all images tags in div
        wrapper = self.soup.find("div", class_="swiper-wrapper")
        if wrapper and isinstance(wrapper, Tag):
            images = wrapper.find_all("img")
        else:
            images = []
        
        # list with photo urls
        list_src_photo = []
        media_group = MediaGroupBuilder(caption=self.full_caption)
        
        # add urls to list
        for src in images:
            list_src_photo.append(src.get("src"))
        
        # if images more then 10 cut to 10
        if len(list_src_photo) > 10:
            del list_src_photo[10:]
        
        # add images_url to media_group
        for photo_url in list_src_photo:
            media_group.add_photo(media=photo_url)
        
        # save images
        self.images = media_group.build() 

    def update_full_caption(self) -> None:
        words = [
            "–í—ñ–¥", "–û—Ç",
            "—è —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫", "—è –≤–ª–∞—Å–Ω–Ω–∏–∫",
            "–ø–æ—Å—Ä–µ–¥–Ω–∏–∫–æ–≤", "—Å–≤–æ—è", "—Å–≤–æ—é",
            "—Ä–∏–µ–ª—Ç–æ—Ä", "—Ä–∏–µ–ª—Ç–æ—Ä–æ–≤",
            "–∞–≥–µ–Ω—Ç—Å—Ç–≤–æ", "–∞–≥–µ–Ω—Ç",
            "–º–∞–∫–ª–µ—Ä", "–ø–æ—Å—Ä–µ–¥–Ω–∏–∫", "–ª–∏—á–Ω—É—é",
            "—Ö–æ–∑—è–∏–Ω", "—Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫", "—Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫–∞",
            "—Ö–æ–∑—è–∏–Ω–∞", "—Ö–æ–∑—è–π–∫–∞", "–±–µ–∑ –∫–æ–º–∏—Å—Å–∏–∏",
            "–∞–≥–µ–Ω—Ç–∞", "–∞–≥–µ–Ω—Ç—Å—Ç–≤–∞", "—Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫–æ–≤",
            "–ø–æ—Å–µ—Ä–µ–¥–Ω–∏–∫—ñ–≤", "—Ä—ñ–µ–ª—Ç–æ—Ä", "—Ä—ñ–µ–ª—Ç–æ—Ä—ñ–≤",
            "–∞–≥–µ–Ω—Ç—Å—Ç–≤–æ", "–º–∞–∫–ª–µ—Ä", "–ø–æ—Å–µ—Ä–µ–¥–Ω–∏–∫",
            "–ø–æ—Å–µ—Ä–µ–¥–Ω–∏–∫", "–æ—Å–æ–±–∏—Å—Ç—É", "–≤–ª–∞—Å–Ω–∏–∫",
            "–≤–ª–∞—Å–Ω–∏–∫–∞", "–≤–ª–∞—Å–Ω–∏–∫—ñ–≤",
            "—Ö–∞–∑—è—ó–Ω", "—Ö–∞–∑—è–π–∫–∞", "–æ—Å–æ–±–∏—Å—Ç—É",
            "–±–µ–∑ –∫–æ–º—ñ—Å—ñ—ó", "–±–µ–∑ —Ä—ñ—î–ª—Ç–æ—Ä—ñ–≤",
            "–∫–æ–º—ñ—Å—ñ–π", "–ë–µ–∑ —Ä–∏–µ–ª—Ç–æ—Ä–æ–≤",
            "–∫–æ–º–∏—Å–∏–π", "–∫–æ–º—ñ—Å—ñ–á", "–∫–æ–º–∏—Å–∏–∏",
        ]

        self.caption = self.delete_words(self.caption, words)
        self.header = self.delete_words(self.header, words)

        captions = (
            f"üè°{self.amount_of_rooms}–∫ –∫–≤\n" f"üè¢–ü–æ–≤–µ—Ä—Ö: {self.floor}\n" f"üîë–ü–ª–æ—â–∞: {self.area}–º2\n" f"üìç–†–∞–π–æ–Ω: {self.district}\n"
        )
        main_caption = f"üí≥Ô∏è{self.price}" f"\n\n{self.header}\n\n" f"üìù–û–ø–∏—Å:\n{self.caption}"

        self.full_caption = captions + main_caption
        self.reset_photo()

    def reset_all(self) -> None:
        self.reset_header()
        self.reset_caption()
        self.reset_price()
        self.reset_main_information()
        self.update_full_caption()

# –û—Ç—Ä–∏–º–∞–Ω–Ω—è –≤—Å—ñ—Ö –¥–∞–Ω–∏—Ö —ñ –∑–∞–ø—É—Å–∫ –Ω–∞–¥—Å–∏–ª–∞–Ω–Ω—è
async def get_data(message: types.Message):
    parser = Parser(url=message.text)
    parser.reset_all()
    print(parser.full_caption)


    # check photo is alright
    new_list = parser.images.copy()
    assert message.bot is not None
    for index in range(len(parser.images)):
        try:
           message_photo = await message.bot.send_media_group(chat_id=-1001902595324, message_thread_id=805, media=[parser.images[index]])
           await message.bot.delete_message(message_id=message_photo[0].message_id, chat_id=-1001902595324)
        except:
           new_list.remove(parser.images[index])
    parser.images = new_list

    await message.answer_media_group(media=parser.images, caption=parser.full_caption, parse_mode="html")
